Create a program that defines two vectors x and y. These will be the Cartesian coordinates of a point. 
Construct a function R that calculates the distance between these points according to the formula R= sqrt(((x2-x1)^2)+((y2-y1)^2)))

Through a subroutine calculate:
1) the gradient using the formula l=(y2-y1)/(x2-x1 )
2) the ordinate b via the formula b=y1-(l*x1)
